{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "d:\\new\\copied_from_c_tmp\\anaconda\\envs\\dm\\lib\\site-packages\\matplotlib\\mpl-data\\stylelib\\_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import urllib.request as urlreq\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import rcParams\n",
    "from pathlib import Path\n",
    "import face_alignment\n",
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_input_file = Path('data/orlando_bloom.avi')\n",
    "video_output_file = Path('data/orlando_bloom_output.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = face_alignment.FaceAlignment(face_alignment.LandmarksType._2D, flip_input=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frames_count 139\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(str(video_input_file))\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "width, height = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH )), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT ))\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "prop_fourcc = int(cap.get(cv2.CAP_PROP_FOURCC))\n",
    "frames_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "prop_format = int(cap.get(cv2.CAP_PROP_FORMAT))\n",
    "\n",
    "# print(f'width {width}, height {height}, fps {fps}, fourcc {prop_fourcc}, format {prop_format}')\n",
    "print(f'frames_count {frames_count}')\n",
    "\n",
    "# Play input video\n",
    "\n",
    "# while(cap.isOpened()):\n",
    "#     ret, frame = cap.read()\n",
    "\n",
    "#     gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "# #     pose_analyzed = analyze_pose(frame)\n",
    "    \n",
    "#     cv2.imshow('frame',gray)\n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_pose(im):\n",
    "    size = im.shape\n",
    "    preds = fa.get_landmarks(im)\n",
    "    \n",
    "    landmarks = preds\n",
    "    im_landmarks = im.copy()\n",
    "    i = 0\n",
    "    for landmark in landmarks:\n",
    "        for x,y in landmark:\n",
    "            if i == 8 or i == 30 or i == 36 or i == 45 or i == 48 or i == 54:\n",
    "                # with white colour in BGR and thickness 1\n",
    "                cv2.circle(im_landmarks, (x, y), 1, (255, 255, 255), 2)\n",
    "            i += 1\n",
    "    \n",
    "    image_points = np.array([\n",
    "                            landmarks[0][30],     # Nose tip\n",
    "                            landmarks[0][8],     # Chin\n",
    "                            landmarks[0][36],     # Left eye left corner\n",
    "                            landmarks[0][45],     # Right eye right corne\n",
    "                            landmarks[0][48],     # Left Mouth corner\n",
    "                            landmarks[0][54]      # Right mouth corner\n",
    "                        ], dtype=\"double\")\n",
    "    \n",
    "    # 3D model points.\n",
    "    model_points = np.array([\n",
    "                                (0.0, 0.0, 0.0),             # Nose tip\n",
    "                                (0.0, -330.0, -65.0),        # Chin\n",
    "                                (-225.0, 170.0, -135.0),     # Left eye left corner\n",
    "                                (225.0, 170.0, -135.0),      # Right eye right corne\n",
    "                                (-150.0, -150.0, -125.0),    # Left Mouth corner\n",
    "                                (150.0, -150.0, -125.0)      # Right mouth corner\n",
    "\n",
    "                            ])\n",
    "\n",
    "\n",
    "    # Camera internals\n",
    "\n",
    "    focal_length = size[1]\n",
    "    center = (size[1]/2, size[0]/2)\n",
    "    camera_matrix = np.array(\n",
    "                             [[focal_length, 0, center[0]],\n",
    "                             [0, focal_length, center[1]],\n",
    "                             [0, 0, 1]], dtype = \"double\"\n",
    "                             )\n",
    "\n",
    "    dist_coeffs = np.zeros((4,1)) # Assuming no lens distortion\n",
    "    (success, rotation_vector, translation_vector) = cv2.solvePnP(model_points, image_points, camera_matrix, dist_coeffs, flags=cv2.SOLVEPNP_ITERATIVE)\n",
    "\n",
    "    \n",
    "    (nose_end_point2D, jacobian) = cv2.projectPoints(np.array([(0.0, 0.0, 1000.0)]), rotation_vector, translation_vector, camera_matrix, dist_coeffs)\n",
    "\n",
    "    for p in image_points:\n",
    "        cv2.circle(im, (int(p[0]), int(p[1])), 3, (0,0,255), -1)\n",
    "\n",
    "\n",
    "    p1 = ( int(image_points[0][0]), int(image_points[0][1]))\n",
    "    p2 = ( int(nose_end_point2D[0][0][0]), int(nose_end_point2D[0][0][1]))\n",
    "\n",
    "    cv2.line(im, p1, p2, (255,0,0), 2)\n",
    "\n",
    "    return im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "# Estimate pose and save file\n",
    "\n",
    "cap = cv2.VideoCapture(video_input_file)\n",
    "# Uncomment line (1) and lines (3) if video from a web camera is to be used\n",
    "# cap = cv2.VideoCapture(0)       # line (1)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "out = cv2.VideoWriter(video_output_file, prop_fourcc, fps, (width, height))\n",
    "\n",
    "i = 0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:  \n",
    "        if (i / fps) * 100 % 10 == 0:\n",
    "            print(f'{i}% complete')\n",
    "        frame = analyze_pose(frame)\n",
    "        \n",
    "#         cv2.imshow('frame',frame)                #lines (3)\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "            \n",
    "        out.write(frame)\n",
    "    else:\n",
    "        break\n",
    "    i += 1\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play result\n",
    "cap = cv2.VideoCapture(video_output_file)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        cv2.imshow('frame',frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
